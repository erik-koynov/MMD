{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ek/spark-2.4.4-bin-hadoop2.7')\n",
    "import pyspark\n",
    "import os\n",
    "java8_location= '/usr/lib/jvm/java-8-openjdk-amd64' # Set your own\n",
    "os.environ['JAVA_HOME'] = java8_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('HW').getOrCreate()\n",
    "spark.conf.set('spark.sql.shuffle.partitions',6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_HASH_FUNCTIONS = 1500 # K\n",
    "N_SETS = 100\n",
    "N_INITIAL = 20000\n",
    "N_TOTAL = 10**5\n",
    "PART_TO_REPLACE = int(N_INITIAL*(2./100))\n",
    "PRIME_NR = 2**31 - 1 # P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_numbers = np.arange(N_TOTAL,dtype = np.int32)\n",
    "np.random.shuffle(all_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = all_numbers[:N_INITIAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_overs = all_numbers[N_INITIAL:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = [(0,np.sort(set_1))]\n",
    "for i in range(1,N_SETS):\n",
    "    random_idx = np.random.choice(np.arange(0, all_sets[i-1][1].shape[0], dtype = int),\n",
    "                                  replace = False,\n",
    "                                  size = PART_TO_REPLACE)\n",
    "\n",
    "    new_set = deepcopy(all_sets[i-1][1])\n",
    "    random_ints = np.random.randint(0,1e5,size = PART_TO_REPLACE)\n",
    "    new_set[random_idx] = random_ints\n",
    "    \n",
    "    all_sets.append((i,np.unique(new_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.sparkContext.parallelize([list(i) for i in all_sets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_integers  = [np.random.randint(0,100,size = 2)for _ in range(RANDOM_HASH_FUNCTIONS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_integers = spark.sparkContext.broadcast(random_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hash the singles from 1 to N (32 bit int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "represent the sets which range from 0 to 1e5 as integers from 1 to N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_shingles(x,N, random_integers, p): # a very basic hash just for the proof of concept\n",
    "    return np.unique(((x*random_integers[0]+random_integers[1])%p)%N)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = dataset.map(lambda x: (x[0],hash_shingles(x[1],N_TOTAL, (1,0), PRIME_NR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final_dict = dict(dataset_final.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the signature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix = dataset.map(lambda x: (x[0],np.array([np.min(hash_shingles(x[1],\n",
    "                                                                     N_TOTAL,\n",
    "                                                i,\n",
    "                                                                    PRIME_NR))\\\n",
    "                                                for i in random_integers.value])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([13,  4,  3, ...,  3,  2, 13], dtype=int32)),\n",
       " (1, array([13,  4,  3, ...,  3,  2, 13], dtype=int32)),\n",
       " (2, array([13,  4,  3, ...,  3,  2, 13], dtype=int32)),\n",
       " (3, array([13,  4,  3, ...,  3,  2, 13], dtype=int32)),\n",
       " (4, array([13,  4,  3, ...,  3,  2, 13], dtype=int32))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_matrix.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix = dict(signature_matrix.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1 = signature_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in signature_matrix.items():\n",
    "    if key == 0:\n",
    "        continue\n",
    "    count = 0\n",
    "    for i, s_ in enumerate(value):\n",
    "        if s_==S_1[i]:\n",
    "            count+=1\n",
    "    print('MinHash similarity S_0:S_{}: {}'.format(key,count/RANDOM_HASH_FUNCTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = dict(all_sets)\n",
    "s_1 = all_sets[0]\n",
    "print(s_1)\n",
    "for key, value in all_sets.items():\n",
    "    if key == 0:\n",
    "        continue\n",
    "    count = 0\n",
    "    total = 0\n",
    "\n",
    "    intersection = len(list(set(s_1).intersection(value)))\n",
    "    union = (len(s_1) + len(value)) - intersection\n",
    "    print('MinHash similarity S_0:S_{}: {}'.format(key,float(intersection) / union))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the relation between the correct choice of parameters for locality sensitive hashing and the probability of false positives/ false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similarities = np.arange(0.1,1,step = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_numbers = np.array([2,3,5,7,20])\n",
    "block_numbers = np.array([10,20,50,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,20))\n",
    "ax = fig.subplots(5,4)\n",
    "fig.tight_layout()\n",
    "for i,row in enumerate(row_numbers):\n",
    "    for j,block in enumerate(block_numbers):\n",
    "        probabilities = 1-(1-jaccard_similarities**row)**block\n",
    "        ax[i,j].plot(jaccard_similarities,probabilities)\n",
    "        ax[i,j].set_title('rows:{} blocks:{}'.format(row,block))\n",
    "        ax[i,j].set_ylabel('probability of being a POSITIVE')\n",
    "        ax[i,j].axvline(x = 0.5,color = 'r')\n",
    "        ax[i,j].axhline(y = 0.5,color = 'g')\n",
    "        ax[i,j].axvline(x=np.interp(0.5,probabilities,jaccard_similarities),color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
